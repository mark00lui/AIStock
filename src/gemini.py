#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Gemini AI è‚¡ç¥¨åˆ†ææ¨¡çµ„
ä½¿ç”¨ Google Gemini API é€²è¡Œè‚¡ç¥¨åˆ†æå’Œå»ºè­°
"""

import json
import requests
import time
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeminiStockAnalyzer:
    """
    Gemini AI è‚¡ç¥¨åˆ†æå™¨
    """
    
    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ– Gemini åˆ†æå™¨
        
        Args:
            api_key (str): Gemini API é‡‘é‘°
        """
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent"
        self.headers = {
            "Content-Type": "application/json"
        }
        
    def _make_api_request(self, prompt: str) -> Optional[Dict[str, Any]]:
        """
        ç™¼é€ API è«‹æ±‚åˆ° Gemini
        
        Args:
            prompt (str): ç™¼é€çµ¦ Gemini çš„æç¤ºè©
            
        Returns:
            Optional[Dict[str, Any]]: API éŸ¿æ‡‰æˆ– None
        """
        try:
            payload = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 2048
                }
            }
            
            url = f"{self.base_url}?key={self.api_key}"
            
            logger.info("ç™¼é€è«‹æ±‚åˆ° Gemini API...")
            response = requests.post(url, headers=self.headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                logger.info("Gemini API è«‹æ±‚æˆåŠŸ")
                return result
            else:
                logger.error(f"API è«‹æ±‚å¤±æ•—: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("API è«‹æ±‚è¶…æ™‚")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"API è«‹æ±‚ç•°å¸¸: {e}")
            return None
        except Exception as e:
            logger.error(f"æœªçŸ¥éŒ¯èª¤: {e}")
            return None
    
    def _extract_json_from_response(self, response: Dict[str, Any], symbol: str = None) -> Optional[Dict[str, Any]]:
        """
        å¾ Gemini éŸ¿æ‡‰ä¸­æå– JSON æ•¸æ“š
        
        Args:
            response (Dict[str, Any]): Gemini API éŸ¿æ‡‰
            symbol (str, optional): è‚¡ç¥¨ä»£ç¢¼ï¼Œç”¨æ–¼å‚™ç”¨ JSON æ§‹å»º
            
        Returns:
            Optional[Dict[str, Any]]: è§£æçš„ JSON æ•¸æ“šæˆ– None
        """
        try:
            if 'candidates' in response and len(response['candidates']) > 0:
                content = response['candidates'][0]['content']
                if 'parts' in content and len(content['parts']) > 0:
                    text = content['parts'][0]['text']
                    
                    # å˜—è©¦æå– JSON éƒ¨åˆ†
                    start_idx = text.find('{')
                    end_idx = text.rfind('}') + 1
                    
                    if start_idx != -1 and end_idx != 0:
                        json_str = text[start_idx:end_idx]
                        
                        # é¦–å…ˆå˜—è©¦ç›´æ¥è§£æ
                        try:
                            return json.loads(json_str)
                        except json.JSONDecodeError as e:
                            logger.error(f"ç›´æ¥è§£æå¤±æ•—: {e}")
                            
                            # å˜—è©¦ç°¡å–®çš„ä¿®å¾©
                            fixed_json = self._simple_json_fix(json_str)
                            try:
                                return json.loads(fixed_json)
                            except json.JSONDecodeError as e2:
                                logger.error(f"ç°¡å–®ä¿®å¾©å¾Œä»ç„¡æ³•è§£æ: {e2}")
                                
                                # å˜—è©¦æ›´æ¿€é€²çš„ä¿®å¾©
                                aggressive_json = self._aggressive_json_fix(json_str)
                                try:
                                    return json.loads(aggressive_json)
                                except json.JSONDecodeError as e3:
                                    logger.error(f"æ¿€é€²ä¿®å¾©å¾Œä»ç„¡æ³•è§£æ: {e3}")
                                    
                                    # æœ€å¾Œå˜—è©¦ï¼šæ‰‹å‹•æ§‹å»ºåŸºæœ¬çµæ§‹
                                    return self._build_fallback_json(symbol, text)
                    else:
                        logger.error("éŸ¿æ‡‰ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON æ ¼å¼")
                        return None
            else:
                logger.error("API éŸ¿æ‡‰æ ¼å¼ä¸æ­£ç¢º")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
            return None
        except Exception as e:
            logger.error(f"æå– JSON æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def _fix_json_format(self, json_str: str) -> str:
        """
        ä¿®å¾©å¸¸è¦‹çš„ JSON æ ¼å¼å•é¡Œ
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        # ä¿®å¾©å¸¸è¦‹çš„æ ¼å¼å•é¡Œ
        json_str = json_str.replace('ï¼Œ', ',')  # ä¸­æ–‡é€—è™Ÿ
        json_str = json_str.replace('ï¼š', ':')  # ä¸­æ–‡å†’è™Ÿ
        json_str = json_str.replace('"', '"')  # æ™ºèƒ½å¼•è™Ÿ
        json_str = json_str.replace('"', '"')  # æ™ºèƒ½å¼•è™Ÿ
        json_str = json_str.replace('' '', "'")  # æ™ºèƒ½å–®å¼•è™Ÿ
        json_str = json_str.replace('' '', "'")  # æ™ºèƒ½å–®å¼•è™Ÿ
        
        # ä¿®å¾©å¤šé¤˜çš„é€—è™Ÿ
        json_str = json_str.replace(',}', '}')
        json_str = json_str.replace(',]', ']')
        
        # ä¿®å¾©ç¼ºå°‘çš„å¼•è™Ÿ
        import re
        # ä¿®å¾©æ²’æœ‰å¼•è™Ÿçš„éµå
        json_str = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_str)
        
        # ç¢ºä¿è¿”å›çš„å­—ç¬¦ä¸²ä¸ç‚ºç©º
        if not json_str.strip():
            return '{"error": "empty_json_string"}'
        
        return json_str
    
    def _simple_json_fix(self, json_str: str) -> str:
        """
        ç°¡å–®çš„ JSON ä¿®å¾©æ–¹æ³•
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        # åŸºæœ¬ä¿®å¾©
        json_str = json_str.replace('ï¼Œ', ',')  # ä¸­æ–‡é€—è™Ÿ
        json_str = json_str.replace('ï¼š', ':')  # ä¸­æ–‡å†’è™Ÿ
        json_str = json_str.replace('"', '"')  # æ™ºèƒ½å¼•è™Ÿ
        json_str = json_str.replace('"', '"')  # æ™ºèƒ½å¼•è™Ÿ
        
        # ä¿®å¾©å¤šé¤˜çš„é€—è™Ÿ
        json_str = json_str.replace(',}', '}')
        json_str = json_str.replace(',]', ']')
        
        # ä¿®å¾©ç¼ºå°‘çš„å¼•è™Ÿ
        import re
        json_str = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_str)
        
        return json_str
    
    def _build_fallback_json(self, symbol: str, original_text: str) -> Dict[str, Any]:
        """
        æ§‹å»ºå‚™ç”¨ JSON çµæ§‹
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç¢¼
            original_text (str): åŸå§‹æ–‡æœ¬
            
        Returns:
            Dict[str, Any]: å‚™ç”¨ JSON çµæ§‹
        """
        logger.warning(f"ä½¿ç”¨å‚™ç”¨ JSON çµæ§‹ for {symbol}")
        
        # å¾åŸå§‹æ–‡æœ¬ä¸­æå–ä¸€äº›åŸºæœ¬ä¿¡æ¯
        sentiment = "ä¸­æ€§"
        if "çœ‹æ¼²" in original_text or "bullish" in original_text.lower():
            sentiment = "çœ‹æ¼²"
        elif "çœ‹è·Œ" in original_text or "bearish" in original_text.lower():
            sentiment = "çœ‹è·Œ"
        
        # æ§‹å»ºç²¾ç°¡çš„ JSON çµæ§‹
        fallback_json = {
             "symbol": symbol,
             "analysis_summary": {
                 "overall_sentiment": sentiment,
                 "confidence_level": "ä¸­",
                 "risk_level": "ä¸­",
                 "time_horizon": "ä¸­æœŸ"
             },
             "future_acquisitions_and_growth_tracks": {
                 "potential_major_acquisitions": ["æ½›åœ¨æ”¶è³¼ç›®æ¨™1", "æ½›åœ¨æ”¶è³¼ç›®æ¨™2", "æ½›åœ¨æ”¶è³¼ç›®æ¨™3"],
                 "acquisition_strategic_importance": "æ”¶è³¼çš„æˆ°ç•¥æ„ç¾©å’Œå½±éŸ¿åˆ†æ",
                 "primary_growth_tracks": ["ä¸»è¦æˆé•·è³½é“1", "ä¸»è¦æˆé•·è³½é“2", "ä¸»è¦æˆé•·è³½é“3"],
                 "growth_track_market_size": "æˆé•·è³½é“å¸‚å ´è¦æ¨¡é ä¼°",
                 "competitive_advantages": ["ç«¶çˆ­å„ªå‹¢1", "ç«¶çˆ­å„ªå‹¢2", "ç«¶çˆ­å„ªå‹¢3"],
                 "strategic_partnerships": ["æˆ°ç•¥åˆä½œ1", "æˆ°ç•¥åˆä½œ2"]
             },
             "growth_track_cagr": {
                 "track_1_cagr_3y": "15%",
                 "track_1_cagr_5y": "12%",
                 "track_2_cagr_3y": "20%",
                 "track_2_cagr_5y": "18%",
                 "track_3_cagr_3y": "25%",
                 "track_3_cagr_5y": "22%",
                 "market_penetration_analysis": "å¸‚å ´æ»²é€ç‡åˆ†æ",
                 "commercialization_timeline": "å•†æ¥­åŒ–æ™‚é–“è¡¨",
                 "growth_catalysts": ["æˆé•·å‚¬åŒ–åŠ‘1", "æˆé•·å‚¬åŒ–åŠ‘2", "æˆé•·å‚¬åŒ–åŠ‘3"]
             },
             "revenue_profit_contribution": {
                 "track_1_revenue_share_3y": "30%",
                 "track_1_revenue_share_5y": "40%",
                 "track_2_revenue_share_3y": "25%",
                 "track_2_revenue_share_5y": "35%",
                 "track_3_revenue_share_3y": "20%",
                 "track_3_revenue_share_5y": "30%",
                 "profit_contribution_analysis": "æ–°è³½é“åˆ©æ½¤ç‡è²¢ç»åˆ†æ",
                 "revenue_structure_transformation": "ç‡Ÿæ”¶çµæ§‹è½‰å‹æ™‚é–“è¡¨",
                 "profit_quality_improvement": "ç²åˆ©è³ªé‡æ”¹å–„æ½›åŠ›"
             },
             "eps_cagr_forecast": {
                 "eps_cagr_1y": "15%",
                 "eps_cagr_3y": "18%",
                 "eps_cagr_5y": "20%",
                 "eps_growth_drivers": ["EPSæˆé•·é©…å‹•åŠ›1", "EPSæˆé•·é©…å‹•åŠ›2", "EPSæˆé•·é©…å‹•åŠ›3"],
                 "profit_margin_expansion": "åˆ©æ½¤ç‡æ“´å¼µé æœŸ",
                 "capex_rd_impact": "è³‡æœ¬æ”¯å‡ºå’Œç ”ç™¼æŠ•å…¥å½±éŸ¿",
                 "eps_scenarios": {
                     "bull_case_eps_cagr": "25%",
                     "base_case_eps_cagr": "18%",
                     "bear_case_eps_cagr": "12%"
                 }
             },
             "stock_price_cagr_forecast": {
                 "price_cagr_1y": "20%",
                 "price_cagr_3y": "25%",
                 "price_cagr_5y": "30%",
                 "valuation_multiple_expansion": "ä¼°å€¼å€æ•¸æ“´å¼µå¯èƒ½æ€§",
                 "market_sentiment_impact": "å¸‚å ´æƒ…ç·’å’ŒæŠ•è³‡è€…èªçŸ¥è®ŠåŒ–",
                 "risk_adjusted_growth": "é¢¨éšªèª¿æ•´å¾Œè‚¡åƒ¹æˆé•·é æœŸ",
                 "price_scenarios": {
                     "bull_case_price_cagr": "35%",
                     "base_case_price_cagr": "25%",
                     "bear_case_price_cagr": "15%"
                 }
             },
             "investment_recommendation": {
                 "action": "æŒæœ‰",
                 "conviction_level": "ä¸­",
                 "target_price": "ç›®æ¨™åƒ¹æ ¼",
                 "time_horizon": "ä¸­æœŸ"
             }
         }
        
        return fallback_json
    
    def _aggressive_json_fix(self, json_str: str) -> str:
        """
        æ›´æ¿€é€²çš„ JSON ä¿®å¾©æ–¹æ³•
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        try:
            # é¦–å…ˆå˜—è©¦ä¿®å¾©å¸¸è¦‹çš„èªæ³•éŒ¯èª¤
            json_str = self._fix_common_syntax_errors(json_str)
            
            # å˜—è©¦æ‰¾åˆ°æœ€å¾Œä¸€å€‹å®Œæ•´çš„ JSON å°è±¡
            brace_count = 0
            last_complete = 0
            
            for i, char in enumerate(json_str):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        last_complete = i + 1
            
            if last_complete > 0:
                return json_str[:last_complete]
            
            # å¦‚æœé‚„æ˜¯ç„¡æ³•æ‰¾åˆ°å®Œæ•´å°è±¡ï¼Œå˜—è©¦æ›´æ¿€é€²çš„ä¿®å¾©
            return self._extreme_json_fix(json_str)
            
        except Exception:
            return json_str
    
    def _fix_common_syntax_errors(self, json_str: str) -> str:
        """
        ä¿®å¾©å¸¸è¦‹çš„ JSON èªæ³•éŒ¯èª¤
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        import re
        
        # ä¿®å¾©ç¼ºå°‘çš„å¼•è™Ÿ
        json_str = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_str)
        
        # ä¿®å¾©å¤šé¤˜çš„é€—è™Ÿ
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        
        # ä¿®å¾©ç¼ºå°‘çš„é€—è™Ÿ
        json_str = re.sub(r'}(\s*")', r'},\1', json_str)
        json_str = re.sub(r'](\s*")', r'],\1', json_str)
        
        # ä¿®å¾©ç¼ºå°‘çš„å¼•è™ŸçµæŸ
        json_str = re.sub(r'([^"])\s*([}\]])', r'\1"\2', json_str)
        
        # ä¿®å¾©å¤šé¤˜çš„å¼•è™Ÿ
        json_str = re.sub(r'""', r'"', json_str)
        
        return json_str
    
    def _extreme_json_fix(self, json_str: str) -> str:
        """
        æ¥µç«¯æƒ…æ³ä¸‹çš„ JSON ä¿®å¾©
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        try:
            # å˜—è©¦æ‰¾åˆ°ç¬¬ä¸€å€‹ { å’Œæœ€å¾Œä¸€å€‹ }
            start = json_str.find('{')
            end = json_str.rfind('}')
            
            if start != -1 and end != -1 and end > start:
                # æå–å¯èƒ½çš„ JSON éƒ¨åˆ†
                potential_json = json_str[start:end+1]
                
                # å˜—è©¦ä¿®å¾©é€™å€‹éƒ¨åˆ†
                fixed_json = self._fix_common_syntax_errors(potential_json)
                
                # é©—è­‰æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ JSON
                try:
                    json.loads(fixed_json)
                    return fixed_json
                except:
                    pass
            
            # å¦‚æœé‚„æ˜¯å¤±æ•—ï¼Œå˜—è©¦åˆ†æ®µä¿®å¾©
            return self._segment_fix(json_str)
            
        except Exception:
            return json_str
    
    def _segment_fix(self, json_str: str) -> str:
        """
        åˆ†æ®µä¿®å¾© JSON
        
        Args:
            json_str (str): åŸå§‹ JSON å­—ç¬¦ä¸²
            
        Returns:
            str: ä¿®å¾©å¾Œçš„ JSON å­—ç¬¦ä¸²
        """
        try:
            # æ‰¾åˆ°æ‰€æœ‰å¯èƒ½çš„ JSON å°è±¡
            import re
            json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', json_str)
            
            if json_objects:
                # å˜—è©¦ä¿®å¾©æœ€å¤§çš„å°è±¡
                largest_object = max(json_objects, key=len)
                fixed_object = self._fix_common_syntax_errors(largest_object)
                
                try:
                    json.loads(fixed_object)
                    return fixed_object
                except:
                    pass
            
            # æœ€å¾Œå˜—è©¦ï¼šç§»é™¤æ‰€æœ‰å¯èƒ½çš„å•é¡Œå­—ç¬¦
            cleaned_json = re.sub(r'[^\x20-\x7E]', '', json_str)  # ç§»é™¤éASCIIå­—ç¬¦
            cleaned_json = re.sub(r',+', ',', cleaned_json)  # ä¿®å¾©å¤šé¤˜é€—è™Ÿ
            cleaned_json = re.sub(r':+', ':', cleaned_json)  # ä¿®å¾©å¤šé¤˜å†’è™Ÿ
            
            return cleaned_json
            
        except Exception:
            return json_str
    
    def analyze_stock(self, symbol: str, current_price: float = None, 
                     company_name: str = None) -> Dict[str, Any]:
        """
        åˆ†æè‚¡ç¥¨ä¸¦è¿”å›çµæ§‹åŒ–çµæœ
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç¢¼
            current_price (float, optional): ç•¶å‰åƒ¹æ ¼
            company_name (str, optional): å…¬å¸åç¨±
            
        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """
        try:
            # æ§‹å»ºåˆ†ææç¤ºè©
            prompt = self._build_analysis_prompt(symbol, current_price, company_name)
            
            # ç™¼é€ API è«‹æ±‚
            response = self._make_api_request(prompt)
            
            if response is None:
                return self._create_error_response("API è«‹æ±‚å¤±æ•—")
            
            # æå– JSON æ•¸æ“š
            result = self._extract_json_from_response(response, symbol)
            
            if result is None:
                return self._create_error_response("ç„¡æ³•è§£æ API éŸ¿æ‡‰")
            
            # æ·»åŠ å…ƒæ•¸æ“š
            result['metadata'] = {
                'symbol': symbol,
                'analysis_date': datetime.now().isoformat(),
                'api_source': 'gemini',
                'status': 'success'
            }
            
            logger.info(f"è‚¡ç¥¨ {symbol} åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æè‚¡ç¥¨ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return self._create_error_response(f"åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    
    def _build_analysis_prompt(self, symbol: str, current_price: float = None, 
                              company_name: str = None) -> str:
        """
        æ§‹å»ºå°ˆæ³¨æ–¼ç¤¾ç¾¤æƒ…ç·’ã€è²¡å ±å’Œæœªä¾†ç™¼å±•çš„åˆ†ææç¤ºè©
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç¢¼
            current_price (float, optional): ç•¶å‰åƒ¹æ ¼
            company_name (str, optional): å…¬å¸åç¨±
            
        Returns:
            str: å®Œæ•´çš„æç¤ºè©
        """
        company_info = f" ({company_name})" if company_name else ""
        price_info = f" ç•¶å‰åƒ¹æ ¼: ${current_price}" if current_price else ""
        
        # æ ¹æ“šè‚¡ç¥¨ä»£ç¢¼æä¾›ç‰¹å®šçš„åˆ†æé‡é»
        company_specific_focus = self._get_company_specific_focus(symbol)
        
        prompt = f"""
 è«‹ä½œç‚ºä¸€ä½è³‡æ·±çš„è‚¡ç¥¨åˆ†æå¸«ï¼Œå° {symbol}{company_info}{price_info} é€²è¡Œç²¾ç°¡è€Œæ·±å…¥çš„æŠ•è³‡åˆ†æã€‚
 
 åˆ†æé‡é»è¦æ±‚ï¼š
 1. å°ˆæ³¨æ–¼æœªä¾†æ½›åœ¨çš„é‡å¤§æ”¶è³¼å’Œæˆé•·è³½é“
 2. é‡é»åˆ†ææ–°è³½é“çš„è¤‡åˆæˆé•·ç‡å’Œå¸‚å ´ä½”æ¯”
 3. æä¾›å…·é«”çš„ EPS å’Œè‚¡åƒ¹è¤‡åˆæˆé•·ç‡é æ¸¬
 4. é¿å…å†—é•·çš„å‚³çµ±åˆ†æï¼Œèšç„¦æ ¸å¿ƒæˆé•·é©…å‹•åŠ›
 
 {company_specific_focus}
 
 åˆ†ææ™‚è«‹ç‰¹åˆ¥é—œæ³¨ä»¥ä¸‹äº”å€‹æ ¸å¿ƒç¶­åº¦ï¼š
 
 1. æœªä¾†æ½›åœ¨çš„é‡å¤§æ”¶è³¼ä»¥åŠæˆé•·è³½é“ï¼š
    - å…¬å¸å¯èƒ½æ”¶è³¼çš„ç›®æ¨™ä¼æ¥­å’Œæˆ°ç•¥æ„ç¾©
    - ä¸»è¦æˆé•·è³½é“çš„å¸‚å ´è¦æ¨¡å’Œç«¶çˆ­å„ªå‹¢
    - æ–°æŠ€è¡“å’Œç”¢å“ç·šçš„ç™¼å±•å‰æ™¯
    - æˆ°ç•¥åˆä½œå’Œè¯ç›Ÿçš„å¯èƒ½æ€§
 
 2. æ–°è³½é“çš„é è¨ˆè¤‡åˆæˆé•·ç‡ï¼š
    - å„æˆé•·è³½é“çš„ä¸‰å¹´å’Œäº”å¹´è¤‡åˆæˆé•·ç‡é æ¸¬
    - å¸‚å ´æ»²é€ç‡å’Œæ¡ç”¨é€Ÿåº¦åˆ†æ
    - æŠ€è¡“æˆç†Ÿåº¦å’Œå•†æ¥­åŒ–æ™‚é–“è¡¨
    - æˆé•·é©…å‹•å› ç´ å’Œå‚¬åŒ–åŠ‘
 
 3. æ–°è³½é“çš„ç‡Ÿæ”¶åŠç²åˆ©ä½”æ¯”ï¼š
    - å„è³½é“åœ¨ç¸½ç‡Ÿæ”¶ä¸­çš„ä½”æ¯”é æ¸¬
    - æ–°è³½é“çš„åˆ©æ½¤ç‡è²¢ç»åˆ†æ
    - ç‡Ÿæ”¶çµæ§‹è½‰å‹çš„æ™‚é–“è¡¨
    - ç²åˆ©è³ªé‡æ”¹å–„çš„æ½›åŠ›
 
 4. æœªä¾†1/3/5å¹´çš„EPSè¤‡åˆæˆé•·ç‡ï¼š
    - åŸºæ–¼æ–°è³½é“ç™¼å±•çš„EPSæˆé•·é æ¸¬
    - åˆ©æ½¤ç‡æ“´å¼µå’Œæˆæœ¬æ§åˆ¶å½±éŸ¿
    - è³‡æœ¬æ”¯å‡ºå’Œç ”ç™¼æŠ•å…¥çš„å½±éŸ¿
    - ä¸åŒæƒ…å¢ƒä¸‹çš„EPSæˆé•·ç¯„åœ
 
 5. æœªä¾†1/3/5å¹´è‚¡åƒ¹è¤‡åˆæˆé•·ç‡ï¼š
    - åŸºæ–¼åŸºæœ¬é¢æ”¹å–„çš„è‚¡åƒ¹æˆé•·é æ¸¬
    - ä¼°å€¼å€æ•¸æ“´å¼µçš„å¯èƒ½æ€§
    - å¸‚å ´æƒ…ç·’å’ŒæŠ•è³‡è€…èªçŸ¥çš„è®ŠåŒ–
    - é¢¨éšªèª¿æ•´å¾Œçš„è‚¡åƒ¹æˆé•·é æœŸ
 
 è«‹ä»¥ä»¥ä¸‹ç²¾ç°¡çš„ JSON æ ¼å¼è¿”å›åˆ†æçµæœï¼Œæ‰€æœ‰åˆ†æå…§å®¹éƒ½å¿…é ˆä½¿ç”¨ä¸­æ–‡è¡¨é”ï¼š

 {{
     "symbol": "{symbol}",
     "analysis_summary": {{
         "overall_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
         "confidence_level": "é«˜/ä¸­/ä½",
         "risk_level": "ä½/ä¸­/é«˜",
         "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ"
     }},
     "future_acquisitions_and_growth_tracks": {{
         "potential_major_acquisitions": ["æ½›åœ¨æ”¶è³¼ç›®æ¨™1", "æ½›åœ¨æ”¶è³¼ç›®æ¨™2", "æ½›åœ¨æ”¶è³¼ç›®æ¨™3"],
         "acquisition_strategic_importance": "æ”¶è³¼çš„æˆ°ç•¥æ„ç¾©å’Œå½±éŸ¿åˆ†æ",
         "primary_growth_tracks": ["ä¸»è¦æˆé•·è³½é“1", "ä¸»è¦æˆé•·è³½é“2", "ä¸»è¦æˆé•·è³½é“3"],
         "growth_track_market_size": "æˆé•·è³½é“å¸‚å ´è¦æ¨¡é ä¼°",
         "competitive_advantages": ["ç«¶çˆ­å„ªå‹¢1", "ç«¶çˆ­å„ªå‹¢2", "ç«¶çˆ­å„ªå‹¢3"],
         "strategic_partnerships": ["æˆ°ç•¥åˆä½œ1", "æˆ°ç•¥åˆä½œ2"]
     }},
     "growth_track_cagr": {{
         "track_1_cagr_3y": "æˆé•·è³½é“1ä¸‰å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_1_cagr_5y": "æˆé•·è³½é“1äº”å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_2_cagr_3y": "æˆé•·è³½é“2ä¸‰å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_2_cagr_5y": "æˆé•·è³½é“2äº”å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_3_cagr_3y": "æˆé•·è³½é“3ä¸‰å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_3_cagr_5y": "æˆé•·è³½é“3äº”å¹´è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "market_penetration_analysis": "å¸‚å ´æ»²é€ç‡åˆ†æ",
         "commercialization_timeline": "å•†æ¥­åŒ–æ™‚é–“è¡¨",
         "growth_catalysts": ["æˆé•·å‚¬åŒ–åŠ‘1", "æˆé•·å‚¬åŒ–åŠ‘2", "æˆé•·å‚¬åŒ–åŠ‘3"]
     }},
     "revenue_profit_contribution": {{
         "track_1_revenue_share_3y": "æˆé•·è³½é“1ä¸‰å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_1_revenue_share_5y": "æˆé•·è³½é“1äº”å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_2_revenue_share_3y": "æˆé•·è³½é“2ä¸‰å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_2_revenue_share_5y": "æˆé•·è³½é“2äº”å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_3_revenue_share_3y": "æˆé•·è³½é“3ä¸‰å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "track_3_revenue_share_5y": "æˆé•·è³½é“3äº”å¹´å¾Œç‡Ÿæ”¶ä½”æ¯”ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "profit_contribution_analysis": "æ–°è³½é“åˆ©æ½¤ç‡è²¢ç»åˆ†æ",
         "revenue_structure_transformation": "ç‡Ÿæ”¶çµæ§‹è½‰å‹æ™‚é–“è¡¨",
         "profit_quality_improvement": "ç²åˆ©è³ªé‡æ”¹å–„æ½›åŠ›"
     }},
     "eps_cagr_forecast": {{
         "eps_cagr_1y": "ä¸€å¹´EPSè¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "eps_cagr_3y": "ä¸‰å¹´EPSè¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "eps_cagr_5y": "äº”å¹´EPSè¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "eps_growth_drivers": ["EPSæˆé•·é©…å‹•åŠ›1", "EPSæˆé•·é©…å‹•åŠ›2", "EPSæˆé•·é©…å‹•åŠ›3"],
         "profit_margin_expansion": "åˆ©æ½¤ç‡æ“´å¼µé æœŸ",
         "capex_rd_impact": "è³‡æœ¬æ”¯å‡ºå’Œç ”ç™¼æŠ•å…¥å½±éŸ¿",
         "eps_scenarios": {{
             "bull_case_eps_cagr": "æ¨‚è§€æƒ…å¢ƒEPSè¤‡åˆæˆé•·ç‡",
             "base_case_eps_cagr": "ä¸­æ€§æƒ…å¢ƒEPSè¤‡åˆæˆé•·ç‡",
             "bear_case_eps_cagr": "ä¿å®ˆæƒ…å¢ƒEPSè¤‡åˆæˆé•·ç‡"
         }}
     }},
     "stock_price_cagr_forecast": {{
         "price_cagr_1y": "ä¸€å¹´è‚¡åƒ¹è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "price_cagr_3y": "ä¸‰å¹´è‚¡åƒ¹è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "price_cagr_5y": "äº”å¹´è‚¡åƒ¹è¤‡åˆæˆé•·ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰",
         "valuation_multiple_expansion": "ä¼°å€¼å€æ•¸æ“´å¼µå¯èƒ½æ€§",
         "market_sentiment_impact": "å¸‚å ´æƒ…ç·’å’ŒæŠ•è³‡è€…èªçŸ¥è®ŠåŒ–",
         "risk_adjusted_growth": "é¢¨éšªèª¿æ•´å¾Œè‚¡åƒ¹æˆé•·é æœŸ",
         "price_scenarios": {{
             "bull_case_price_cagr": "æ¨‚è§€æƒ…å¢ƒè‚¡åƒ¹è¤‡åˆæˆé•·ç‡",
             "base_case_price_cagr": "ä¸­æ€§æƒ…å¢ƒè‚¡åƒ¹è¤‡åˆæˆé•·ç‡",
             "bear_case_price_cagr": "ä¿å®ˆæƒ…å¢ƒè‚¡åƒ¹è¤‡åˆæˆé•·ç‡"
         }}
     }},
     "investment_recommendation": {{
         "action": "è²·å…¥/æŒæœ‰/è³£å‡º",
         "conviction_level": "é«˜/ä¸­/ä½",
         "target_price": "å…·é«”åƒ¹æ ¼",
         "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ"
     }}
         }}

 åˆ†æè¦æ±‚ï¼š
 1. å°ˆæ³¨æ–¼æœªä¾†æ½›åœ¨çš„é‡å¤§æ”¶è³¼å’Œæˆé•·è³½é“åˆ†æ
 2. æä¾›å…·é«”çš„æ–°è³½é“è¤‡åˆæˆé•·ç‡é æ¸¬
 3. åˆ†ææ–°è³½é“çš„ç‡Ÿæ”¶å’Œç²åˆ©ä½”æ¯”è®ŠåŒ–
 4. çµ¦å‡º1/3/5å¹´çš„EPSè¤‡åˆæˆé•·ç‡é æ¸¬
 5. æä¾›1/3/5å¹´çš„è‚¡åƒ¹è¤‡åˆæˆé•·ç‡é æ¸¬
 6. åˆ†æå¿…é ˆåŸºæ–¼æœ€æ–°çš„å¸‚å ´å‹•æ…‹å’Œå…¬å¸ç™¼å±•
 7. é¿å…å†—é•·çš„å‚³çµ±åˆ†æï¼Œèšç„¦æ ¸å¿ƒæˆé•·é©…å‹•åŠ›
 8. è¿”å›æ ¼å¼å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSONï¼Œæ‰€æœ‰æè¿°å¿…é ˆå…·é«”
 9. æ‰€æœ‰åˆ†æçµæœéƒ½å¿…é ˆä½¿ç”¨ä¸­æ–‡è¡¨é”
 10. æä¾›æ¨‚è§€ã€ä¸­æ€§ã€ä¿å®ˆä¸‰ç¨®æƒ…å¢ƒçš„é æ¸¬
 
 åªè¿”å› JSON æ ¼å¼çš„çµæœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—èªªæ˜ã€‚
"""
        
        return prompt
    
    def _get_company_specific_focus(self, symbol: str) -> str:
        """
        æ ¹æ“šè‚¡ç¥¨ä»£ç¢¼ç²å–é€šç”¨çš„AIè³½é“åˆ†æé‡é»
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            str: é€šç”¨AIè³½é“åˆ†æé‡é»èªªæ˜
        """
        return f"""
é‡å° {symbol} çš„é€šç”¨AIè³½é“åˆ†æé‡é»ï¼š

æœªä¾†äº”å¹´ç‡Ÿæ”¶å‹•åŠ›åˆ†æ - åŸºæ–¼AIæ”¹é©çš„äºŒåå€‹æ ¸å¿ƒç™¼å±•æ–¹å‘ï¼š

1. AIåŸºç¤è¨­æ–½èˆ‡æŠ€è¡“ï¼š
   - æ”¶è³¼LLMå…¬å¸ï¼šè©•ä¼°æ”¶è³¼å¤§å‹èªè¨€æ¨¡å‹åˆå‰µå…¬å¸çš„æˆ°ç•¥åƒ¹å€¼å’Œæ•´åˆæ½›åŠ›
   - é›²æ“´å±•ï¼šAIé›²æœå‹™çš„å¸‚å ´æ“´å¼µå’Œä¼æ¥­æ¡ç”¨ç‡æå‡
   - AIé›»åŠ›ï¼šAIå„ªåŒ–çš„é›»åŠ›ç®¡ç†å’Œæ™ºèƒ½é›»ç¶²æŠ€è¡“
   - æ¨è«–ASICï¼šå°ˆç”¨AIæ¨ç†æ™¶ç‰‡çš„é–‹ç™¼å’Œå•†æ¥­åŒ–
   - è³‡æ–™ä¸­å¿ƒ+æ¨è«–ä¸­å¿ƒASICåŒ–ï¼šæ•¸æ“šä¸­å¿ƒå‘AIå°ˆç”¨æ¶æ§‹è½‰å‹

2. AIæ‡‰ç”¨é ˜åŸŸï¼š
   - AIé†«ç™‚ï¼šé†«ç™‚è¨ºæ–·ã€è—¥ç‰©ç ”ç™¼ã€å€‹æ€§åŒ–æ²»ç™‚çš„AIæ‡‰ç”¨
   - AIæ©Ÿå™¨äººï¼šå·¥æ¥­è‡ªå‹•åŒ–ã€æœå‹™æ©Ÿå™¨äººã€äººå½¢æ©Ÿå™¨äººæŠ€è¡“
   - AI XRçœ¼é¡ï¼šå¢å¼·ç¾å¯¦å’Œè™›æ“¬ç¾å¯¦çš„AIæ•´åˆæ‡‰ç”¨
   - ROBOTAXIèˆ‡æ©Ÿå™¨äººï¼šè‡ªå‹•é§•é§›è¨ˆç¨‹è»Šå’Œæ©Ÿå™¨äººæœå‹™
   - ç”¢ç·šé€²ä¸€æ­¥è‡ªå‹•åŒ–ï¼šè£½é€ æ¥­çš„AIé©…å‹•è‡ªå‹•åŒ–å‡ç´š

3. AIé‡‘èèˆ‡æ•¸å­—è³‡ç”¢ï¼š
   - AIé‡‘èï¼šæ™ºèƒ½æŠ•é¡§ã€é¢¨éšªç®¡ç†ã€æ¬ºè©æª¢æ¸¬çš„AIæ‡‰ç”¨
   - ç©©å®šå¹£ï¼šAIé©…å‹•çš„ç©©å®šå¹£ç®—æ³•å’Œç›£ç®¡æŠ€è¡“
   - åŠ å¯†è²¨å¹£ï¼šAIåœ¨åŠ å¯†è²¨å¹£äº¤æ˜“å’Œå€å¡ŠéˆæŠ€è¡“ä¸­çš„æ‡‰ç”¨

4. AIå‚ç›´æ•´åˆï¼š
   - AIæ•™è‚²ï¼šå€‹æ€§åŒ–å­¸ç¿’ã€æ™ºèƒ½è¼”å°ã€æ•™è‚²å…§å®¹ç”Ÿæˆ
   - AIå¨›æ¨‚ï¼šå…§å®¹å‰µä½œã€éŠæˆ²AIã€å¨›æ¨‚é«”é©—å€‹æ€§åŒ–
   - AIé›¶å”®ï¼šæ™ºèƒ½æ¨è–¦ã€åº«å­˜ç®¡ç†ã€å®¢æˆ¶æœå‹™è‡ªå‹•åŒ–
   - AIç‰©æµï¼šä¾›æ‡‰éˆå„ªåŒ–ã€é…é€è·¯ç·šè¦åŠƒã€å€‰å„²è‡ªå‹•åŒ–
   - AIè¾²æ¥­ï¼šç²¾æº–è¾²æ¥­ã€ä½œç‰©ç›£æ§ã€è¾²æ¥­æ©Ÿå™¨äºº

5. AIæ•ˆç‡æå‡ï¼š
   - AIå®¢æœï¼šæ™ºèƒ½å®¢æœç³»çµ±å’Œå®¢æˆ¶é«”é©—å„ªåŒ–
   - AIç ”ç™¼ï¼šç ”ç™¼æµç¨‹è‡ªå‹•åŒ–å’Œå‰µæ–°åŠ é€Ÿ
   - AIç‡ŸéŠ·ï¼šç²¾æº–ç‡ŸéŠ·ã€å…§å®¹ç”Ÿæˆã€å¸‚å ´åˆ†æ
   - AIæ³•å‹™ï¼šæ³•å¾‹æ–‡æª”åˆ†æã€åˆè¦ç›£æ§ã€æ™ºèƒ½åˆç´„

æˆé•·è³½é“åˆ†æé‡é»ï¼š
- è©•ä¼°å…¬å¸åœ¨ä¸Šè¿°20å€‹AIè³½é“ä¸­çš„åƒèˆ‡åº¦å’Œç«¶çˆ­å„ªå‹¢
- åˆ†æAIæŠ€è¡“å°ç¾æœ‰æ¥­å‹™çš„æ”¹é€ æ½›åŠ›å’Œæ–°æ¥­å‹™é–‹æ‹“æ©Ÿæœƒ
- é æ¸¬AIæŠ•è³‡å°ç‡Ÿæ”¶çµæ§‹å’Œåˆ©æ½¤ç‡çš„å½±éŸ¿
- è©•ä¼°AIæŠ€è¡“çš„å•†æ¥­åŒ–æ™‚é–“è¡¨å’Œå¸‚å ´æ¥å—åº¦

ä¼°å€¼é‡é»ï¼š
- AIæŠ€è¡“å°å…¬å¸ä¼°å€¼å€æ•¸çš„æ½›åœ¨æå‡
- AIæŠ•è³‡çš„è³‡æœ¬å›å ±ç‡å’Œé¢¨éšªèª¿æ•´æ”¶ç›Š
- å‚³çµ±æ¥­å‹™AIåŒ–è½‰å‹çš„æˆæœ¬æ•ˆç›Šåˆ†æ
- æ–°AIæ¥­å‹™çš„å¸‚å ´è¦æ¨¡å’Œç«¶çˆ­æ ¼å±€è©•ä¼°
- AIæŠ€è¡“å£å£˜å’Œå¯æŒçºŒç«¶çˆ­å„ªå‹¢åˆ†æ

æˆæœ¬ä¸‹é™æ½›åŠ›åˆ†æï¼š
- AIè‡ªå‹•åŒ–å°äººåŠ›æˆæœ¬çš„ç¯€çœ
- AIå„ªåŒ–å°ç‡Ÿé‹æ•ˆç‡çš„æå‡
- AIé æ¸¬å°åº«å­˜å’Œä¾›æ‡‰éˆæˆæœ¬çš„é™ä½
- AIå€‹æ€§åŒ–å°ç‡ŸéŠ·æˆæœ¬çš„å„ªåŒ–
- AIç›£æ§å°é¢¨éšªå’Œåˆè¦æˆæœ¬çš„æ¸›å°‘
"""
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """
        å‰µå»ºéŒ¯èª¤éŸ¿æ‡‰
        
        Args:
            error_message (str): éŒ¯èª¤ä¿¡æ¯
            
        Returns:
            Dict[str, Any]: éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼
        """
        return {
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "api_source": "gemini",
                "status": "error"
            },
            "error": {
                "message": error_message,
                "type": "api_error"
            }
        }
    
    def get_stock_news_analysis(self, symbol: str, news_count: int = 5) -> Dict[str, Any]:
        """
        åˆ†æè‚¡ç¥¨ç›¸é—œæ–°è
        
        Args:
            symbol (str): è‚¡ç¥¨ä»£ç¢¼
            news_count (int): åˆ†æçš„æ–°èæ•¸é‡
            
        Returns:
            Dict[str, Any]: æ–°èåˆ†æçµæœ
        """
        prompt = f"""
è«‹ä½œç‚ºä¸€ä½è³‡æ·±çš„è²¡ç¶“æ–°èåˆ†æå¸«ï¼Œå° {symbol} ç›¸é—œçš„æœ€æ–°æ–°èã€å¸‚å ´å‹•æ…‹å’Œç¤¾ç¾¤è¨è«–é€²è¡Œå…¨é¢åˆ†æã€‚

åˆ†ææ™‚è«‹ç‰¹åˆ¥é—œæ³¨ä»¥ä¸‹ç¶­åº¦ï¼š

1. æ–°èå½±éŸ¿åˆ†æï¼š
   - è²¡å ±ç›¸é—œæ–°èå’Œæ¥­ç¸¾æŒ‡å¼•
   - ç®¡ç†å±¤è®Šå‹•å’Œå…¬å¸ç­–ç•¥èª¿æ•´
   - ç”¢å“ç™¼å¸ƒå’ŒæŠ€è¡“å‰µæ–°
   - ä½µè³¼ã€åˆä½œå’Œæˆ°ç•¥æŠ•è³‡

2. ç›£ç®¡å’Œæ³•å¾‹æ–°èï¼š
   - ç›£ç®¡èª¿æŸ¥å’Œåˆè¦å•é¡Œ
   - æ³•å¾‹è¨´è¨Ÿå’Œå°ˆåˆ©ç³¾ç´›
   - æ”¿ç­–è®ŠåŒ–å’Œæ³•è¦å½±éŸ¿
   - åå£Ÿæ–·å’Œç«¶çˆ­æ³•è¦

3. å¸‚å ´å’Œç«¶çˆ­å‹•æ…‹ï¼š
   - ç«¶çˆ­å°æ‰‹å‹•æ…‹
   - å¸‚å ´ä»½é¡è®ŠåŒ–
   - è¡Œæ¥­è¶¨å‹¢å’ŒæŠ€è¡“è®Šé©
   - ä¾›æ‡‰éˆå’Œåˆä½œå¤¥ä¼´æ–°è

4. å®è§€ç¶“æ¿Ÿå½±éŸ¿ï¼š
   - åˆ©ç‡æ”¿ç­–å½±éŸ¿
   - é€šè²¨è†¨è„¹å’Œç¶“æ¿ŸæŒ‡æ¨™
   - åœ°ç·£æ”¿æ²»é¢¨éšª
   - åŒ¯ç‡å’Œè²¿æ˜“æ”¿ç­–

5. ç¤¾ç¾¤å’Œæ•£æˆ¶æƒ…ç·’ï¼š
   - ç¤¾ç¾¤åª’é«”è¨è«–ç†±åº¦
   - æ•£æˆ¶æŠ•è³‡è€…æƒ…ç·’è®ŠåŒ–
   - ç¶²ç´…å’Œæ„è¦‹é ˜è¢–è§€é»
   - æœŸæ¬Šå’Œè¡ç”Ÿå“æ´»å‹•

è«‹ä»¥ä»¥ä¸‹å¢å¼· JSON æ ¼å¼è¿”å›åˆ†æçµæœï¼Œæ‰€æœ‰åˆ†æå…§å®¹éƒ½å¿…é ˆä½¿ç”¨ä¸­æ–‡è¡¨é”ï¼š

{{
    "symbol": "{symbol}",
    "news_analysis_summary": {{
        "overall_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
        "news_impact_level": "é«˜/ä¸­/ä½",
        "market_reaction_expectation": "æ­£é¢/è² é¢/ä¸­æ€§",
        "confidence_level": "é«˜/ä¸­/ä½",
        "time_horizon": "ç«‹å³/çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ"
    }},
    "key_news_categories": {{
        "earnings_related": {{
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "impact": "é«˜/ä¸­/ä½",
            "key_events": ["å…·é«”äº‹ä»¶1", "å…·é«”äº‹ä»¶2"]
        }},
        "regulatory_legal": {{
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "impact": "é«˜/ä¸­/ä½",
            "key_events": ["å…·é«”äº‹ä»¶1", "å…·é«”äº‹ä»¶2"]
        }},
        "business_development": {{
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "impact": "é«˜/ä¸­/ä½",
            "key_events": ["å…·é«”äº‹ä»¶1", "å…·é«”äº‹ä»¶2"]
        }},
        "market_competition": {{
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "impact": "é«˜/ä¸­/ä½",
            "key_events": ["å…·é«”äº‹ä»¶1", "å…·é«”äº‹ä»¶2"]
        }},
        "macro_economic": {{
            "sentiment": "æ­£é¢/è² é¢/ä¸­æ€§",
            "impact": "é«˜/ä¸­/ä½",
            "key_events": ["å…·é«”äº‹ä»¶1", "å…·é«”äº‹ä»¶2"]
        }}
    }},
    "detailed_news_analysis": [
        {{
            "event_title": "å…·é«”æ–°èæ¨™é¡Œ",
            "event_date": "äº‹ä»¶æ—¥æœŸæˆ–æ™‚é–“ç¯„åœ",
            "news_source": "æ–°èä¾†æº",
            "sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
            "impact_significance": "é«˜/ä¸­/ä½",
            "market_relevance": "é«˜/ä¸­/ä½",
            "detailed_description": "è©³ç´°çš„äº‹ä»¶æè¿°å’ŒèƒŒæ™¯",
            "potential_impact": "å°è‚¡åƒ¹çš„æ½›åœ¨å½±éŸ¿åˆ†æ",
            "risk_factors": ["ç›¸é—œé¢¨éšªå› ç´ 1", "ç›¸é—œé¢¨éšªå› ç´ 2"],
            "opportunity_factors": ["ç›¸é—œæ©Ÿæœƒå› ç´ 1", "ç›¸é—œæ©Ÿæœƒå› ç´ 2"]
        }}
    ],
    "sentiment_breakdown": {{
        "bullish_factors": ["å…·é«”çœ‹æ¼²å› ç´ 1", "å…·é«”çœ‹æ¼²å› ç´ 2", "å…·é«”çœ‹æ¼²å› ç´ 3"],
        "bearish_factors": ["å…·é«”çœ‹è·Œå› ç´ 1", "å…·é«”çœ‹è·Œå› ç´ 2", "å…·é«”çœ‹è·Œå› ç´ 3"],
        "neutral_factors": ["å…·é«”ä¸­æ€§å› ç´ 1", "å…·é«”ä¸­æ€§å› ç´ 2"],
        "uncertainty_factors": ["ä¸ç¢ºå®šæ€§å› ç´ 1", "ä¸ç¢ºå®šæ€§å› ç´ 2"]
    }},
    "market_implications": {{
        "short_term_outlook": "çŸ­æœŸå¸‚å ´å±•æœ›",
        "medium_term_outlook": "ä¸­æœŸå¸‚å ´å±•æœ›",
        "long_term_outlook": "é•·æœŸå¸‚å ´å±•æœ›",
        "price_target_impact": "å°ç›®æ¨™åƒ¹æ ¼çš„å½±éŸ¿",
        "volatility_expectation": "é æœŸæ³¢å‹•æ€§è®ŠåŒ–",
        "trading_volume_impact": "å°äº¤æ˜“é‡çš„å½±éŸ¿"
    }},
    "risk_assessment": {{
        "high_risk_events": ["é«˜é¢¨éšªäº‹ä»¶1", "é«˜é¢¨éšªäº‹ä»¶2"],
        "medium_risk_events": ["ä¸­é¢¨éšªäº‹ä»¶1", "ä¸­é¢¨éšªäº‹ä»¶2"],
        "low_risk_events": ["ä½é¢¨éšªäº‹ä»¶1", "ä½é¢¨éšªäº‹ä»¶2"],
        "risk_mitigation_factors": ["é¢¨éšªç·©è§£å› ç´ 1", "é¢¨éšªç·©è§£å› ç´ 2"]
    }},
    "opportunity_analysis": {{
        "high_opportunity_events": ["é«˜æ©Ÿæœƒäº‹ä»¶1", "é«˜æ©Ÿæœƒäº‹ä»¶2"],
        "medium_opportunity_events": ["ä¸­æ©Ÿæœƒäº‹ä»¶1", "ä¸­æ©Ÿæœƒäº‹ä»¶2"],
        "low_opportunity_events": ["ä½æ©Ÿæœƒäº‹ä»¶1", "ä½æ©Ÿæœƒäº‹ä»¶2"],
        "opportunity_catalysts": ["æ©Ÿæœƒå‚¬åŒ–åŠ‘1", "æ©Ÿæœƒå‚¬åŒ–åŠ‘2"]
    }},
    "community_sentiment": {{
        "social_media_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
        "retail_investor_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
        "institutional_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
        "analyst_sentiment": "çœ‹æ¼²/çœ‹è·Œ/ä¸­æ€§",
        "key_discussion_topics": ["ç†±é–€è¨è«–è©±é¡Œ1", "ç†±é–€è¨è«–è©±é¡Œ2"]
    }},
    "data_sources": {{
        "news_sources": ["è·¯é€ç¤¾", "å½­åšç¤¾", "CNBC", "å…¶ä»–ä¾†æº"],
        "social_media_platforms": ["Reddit", "Twitter", "StockTwits", "å…¶ä»–å¹³å°"],
        "analyst_reports": ["åˆ†æå¸«å ±å‘Šä¾†æº1", "åˆ†æå¸«å ±å‘Šä¾†æº2"],
        "regulatory_filings": ["ç›£ç®¡æ–‡ä»¶ä¾†æº1", "ç›£ç®¡æ–‡ä»¶ä¾†æº2"]
    }}
}}

åˆ†æè¦æ±‚ï¼š
1. åŸºæ–¼æœ€æ–°çš„æ–°èå ±å°ã€ç¤¾ç¾¤è¨è«–å’Œåˆ†æå¸«è§€é»
2. æä¾›å…·é«”çš„å½±éŸ¿è©•ä¼°å’Œå¸‚å ´åæ‡‰é æœŸ
3. è€ƒæ…®æ–°èçš„æ™‚é–“æ•æ„Ÿæ€§å’ŒæŒçºŒå½±éŸ¿
4. åˆ†æå¿…é ˆå®¢è§€ã€å…¨é¢ï¼Œé¿å…éåº¦åæ‡‰
5. è¿”å›æ ¼å¼å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSONï¼Œæ‰€æœ‰æè¿°å¿…é ˆå…·é«”
6. æ‰€æœ‰åˆ†æçµæœéƒ½å¿…é ˆä½¿ç”¨ä¸­æ–‡è¡¨é”ï¼ŒåŒ…æ‹¬æ‰€æœ‰æŒ‡æ¨™ã€å»ºè­°å’Œæè¿°

åªè¿”å› JSON æ ¼å¼çš„çµæœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—èªªæ˜ã€‚
"""
        
        try:
            response = self._make_api_request(prompt)
            
            if response is None:
                return self._create_error_response("æ–°èåˆ†æ API è«‹æ±‚å¤±æ•—")
            
            result = self._extract_json_from_response(response)
            
            if result is None:
                return self._create_error_response("ç„¡æ³•è§£ææ–°èåˆ†æéŸ¿æ‡‰")
            
            result['metadata'] = {
                'symbol': symbol,
                'analysis_date': datetime.now().isoformat(),
                'api_source': 'gemini',
                'analysis_type': 'news',
                'status': 'success'
            }
            
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æ {symbol} æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return self._create_error_response(f"æ–°èåˆ†æéŒ¯èª¤: {str(e)}")


def test_gemini_analyzer():
    """
    æ¸¬è©¦ Gemini åˆ†æå™¨
    """
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦ Gemini è‚¡ç¥¨åˆ†æå™¨...")
    
    # è«‹æ›¿æ›ç‚ºæ‚¨çš„å¯¦éš› API é‡‘é‘°
    api_key = input("è«‹è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°: ").strip()
    
    if not api_key:
        print("âŒ æœªæä¾› API é‡‘é‘°ï¼Œæ¸¬è©¦çµ‚æ­¢")
        return
    
    # å‰µå»ºåˆ†æå™¨å¯¦ä¾‹
    analyzer = GeminiStockAnalyzer(api_key)
    
    # æ¸¬è©¦è‚¡ç¥¨åˆ—è¡¨
    test_stocks = [
        {"symbol": "AAPL", "price": 150.0, "name": "Apple Inc."},
        {"symbol": "GOOGL", "price": 2800.0, "name": "Alphabet Inc."},
        {"symbol": "TSLA", "price": 800.0, "name": "Tesla Inc."}
    ]
    
    print(f"\nğŸ“Š é–‹å§‹åˆ†æ {len(test_stocks)} æ”¯è‚¡ç¥¨...")
    
    for i, stock in enumerate(test_stocks, 1):
        print(f"\nğŸ” åˆ†æè‚¡ç¥¨ {i}/{len(test_stocks)}: {stock['symbol']}")
        
        try:
            # é€²è¡Œè‚¡ç¥¨åˆ†æ
            result = analyzer.analyze_stock(
                symbol=stock['symbol'],
                current_price=stock['price'],
                company_name=stock['name']
            )
            
            if result.get('metadata', {}).get('status') == 'success':
                print(f"âœ… {stock['symbol']} åˆ†ææˆåŠŸ")
                
                # é¡¯ç¤ºé—œéµä¿¡æ¯
                analysis = result.get('analysis_summary', {})
                recommendation = result.get('investment_recommendation', {})
                
                print(f"   æ•´é«”æƒ…ç·’: {analysis.get('overall_sentiment', 'N/A')}")
                print(f"   ä¿¡å¿ƒç­‰ç´š: {analysis.get('confidence_level', 'N/A')}")
                print(f"   å»ºè­°å‹•ä½œ: {recommendation.get('action', 'N/A')}")
                print(f"   ç›®æ¨™åƒ¹æ ¼: {recommendation.get('target_price', 'N/A')}")
                
                # ä¿å­˜çµæœåˆ°æ–‡ä»¶
                filename = f"gemini_analysis_{stock['symbol']}.json"
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"   ğŸ“„ çµæœå·²ä¿å­˜åˆ°: {filename}")
                
            else:
                print(f"âŒ {stock['symbol']} åˆ†æå¤±æ•—")
                error_msg = result.get('error', {}).get('message', 'æœªçŸ¥éŒ¯èª¤')
                print(f"   éŒ¯èª¤ä¿¡æ¯: {error_msg}")
            
            # æ·»åŠ å»¶é²é¿å… API é™åˆ¶
            if i < len(test_stocks):
                print("   â³ ç­‰å¾… 3 ç§’å¾Œç¹¼çºŒ...")
                time.sleep(3)
                
        except Exception as e:
            print(f"âŒ åˆ†æ {stock['symbol']} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
    
    print(f"\nğŸ‰ Gemini åˆ†æå™¨æ¸¬è©¦å®Œæˆï¼")
    print("ğŸ“ è«‹æª¢æŸ¥ç•¶å‰ç›®éŒ„ä¸­çš„ JSON æ–‡ä»¶æŸ¥çœ‹è©³ç´°çµæœ")


if __name__ == "__main__":
    test_gemini_analyzer()
